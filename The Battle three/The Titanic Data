### 前言：

    到今天为止，datascinence 已经学的差不多了，我觉得可以上手实战了，下边是从kaggle竞赛网上拿到的第一个数据集：泰坦尼克号的获救数据。主要是通过乘
客等级，姓名，性别，船票费，亲属人数等数据来预测样本客户是否能获救。（github上粘图片有点麻烦，所以就先不放图片了）

### 结论：

    这是我入手的第一个数据集，所以各方面的分析，挖掘，可能不是很到位。但是最后模型的预测效果还是很满意的，正确率有76%左右，在kaggle上排名7165名，我
也不知道是碰运气还是真的分析的很对，这个排名对我来说已经是很满足了。（我原设想的正确率有70%就已经很知足了）

### 模型选择：

    看了训练数据之后，发现是二分类问题，第一个想法就是logisticRegression,随后又在脑子里想了一写别的二分类算法，SVM，树算法等，但考虑到是第一次实战
所以先选了一个简单的算法————LogisticRegression(这个简单的就用了我一上午的时间来拟合)

### 数据分析：

    首先，打开train.csv文件，我们会看到一系列的指标，包括乘客编号，姓名，性别等等，因为本文，只是为了记录我自己的实战经验，并不是教程，所以在这里
不一一列举了，然后开始数据规约嘛，下边是我对数据的理解：
    1）性别，在电影里，我们都看过，老船长说的那句话：“让妇女和儿童先走！”，所以本次分析也结合了这个事实，先用py的一个模块叫matplotlib.pyplot，画
了一下性别的获救分布，发现果然女性的获救几率远大于男性。
    2）年龄，前边说到了儿童，那么我们也看看年龄和获救的数量分布，本以为会老人和小孩的获救概率高，青壮年忙着救人会低一些，但是画图之后发现，老人的获
救数量是最低的，儿童是最高的，造成这样的分布，可能是老人的体力不支，导致无法快速获救吧。
    3）乘客等级，这个社会果然是越有钱越好，画图能够发现等级高的乘客获救数量明显高于等级低的客户。
    4）票价：这个和客户等级有些相关，所以也看作是我的变量之一。
    5）亲属人数：这个亲属人数有两个字段，一个是兄弟姐妹，一个是家人，有家人的意志会坚定一些，获救几率应该会大一些，其实很多人在泰坦尼克灾难中是被冻
死的，而不是受到伤害而亡的。
    以上是我选择的参数，当然看了网上别人的分析，有些还把离港口岸，姓氏什么，座位的位置也做为了变量，其实仔细想想是有道理的，靠近撞击点的座位肯定生还
几率小，但是这些很隐晦的变量，我不是很熟悉，所以本次先放弃掉了。

### 数据预处理

    1）性别：因为用到的是逻辑回归模型，所以要尽可能的划分thetaX的正负，所以我将女性设置为1，男性设置为-1，网上很多设置的是0和1，但是我认识1和-1拟
合的更好一点，因为逻辑回归是正负的问题嘛。
    2）年龄：这是我耗费时间最长的第一个字段，以前看的网上或者书上的资料，对这中缺失值不是很非常大的，都会采用众数，平均数等来填充，但是我考虑到年龄
的影响在该事件中还是非常大的，毕竟‘儿童和妇女先走’，所以我先计算了17岁以下，18--36岁之间，37岁以上的各区间概率，然后把缺失的175个样本，按这个概率分
配进去，取各段的中位数。
    3）票价：当然零标准化啦，简单处理一下到0,1之间，很简单。
    4）至于其他的亲属人数，乘客等级，是很正常的int，所以就没预处理。

### 模型拟合

    1）模型拟合用的事sklearn的包，tensoflow还没有入手。
    2）正确率是76%，这个正确率对我来说还算合格，但实际情况来看，坑你还有很多需要在优化的地方。
    
### 总结
    数据挖掘的过程我觉得很重要的一部分是数据与处理，在网上也看到了针对这个泰坦尼克数据集各式各样的预处理方法，感觉想法真的很重要，能把名字的姓氏当做
变量的那个牛人真的很厉害，他主要是通过姓氏是否一样来赋值，一样的话就说明他们之间可能是亲戚，互帮互助。这种思想，我之前是没有的，看到Name 我就会删掉，
（一个人的命运，怎么可能会跟他叫什么有关），以后这种方面也会多考虑一下。

